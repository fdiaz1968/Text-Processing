{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentos de Procesamiento Tectual \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vttFPaF4J0uk"
   },
   "source": [
    "# I. Cargando **\"quanteda\"** y nuestro primer ***corpus***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 107078,
     "status": "ok",
     "timestamp": 1689008501733,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "VVfmvaX_PTgx",
    "outputId": "7fc1f15e-31e0-495b-e53a-34594d78f838",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Package version: 3.3.1\n",
      "Unicode version: 13.0\n",
      "ICU version: 69.1\n",
      "\n",
      "Parallel computing: 20 of 20 threads used.\n",
      "\n",
      "See https://quanteda.io for tutorials and examples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# install.packages(\"quanteda\")\n",
    "library(quanteda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Que es un Corpus?\n",
    "\n",
    "En lingüística y procesamiento del lenguaje natural, un \"corpus\" se refiere a una colección estructurada y organizada de textos escritos o hablados que se utilizan para el estudio, análisis y entrenamiento de modelos de lenguaje.\n",
    "\n",
    "Un corpus puede estar compuesto por una variedad de textos, como libros, artículos, periódicos, transcripciones de audio, conversaciones grabadas, páginas web, entre otros. Estos textos pueden estar etiquetados con **metadatos** (*docvars*) para facilitar su búsqueda y análisis.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShCC_QYoW1FK"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Corpus: data_corpus_inaugural\n",
    "\n",
    "Los discursos inaugurales son pronunciados por los presidentes de Estados Unidos cuando juran su cargo, algo que ocurre una vez cada cuatro años, el 21 de enero. Generalmente, contienen mensajes importantes sobre sus intenciones, prioridades y visión para el país.\n",
    "\n",
    "Este corpus es ampliamente utilizado en el campo del procesamiento del lenguaje natural y la lingüística computacional como una fuente de datos para entrenar y evaluar modelos de análisis de texto, clasificación de sentimientos, extracción de características lingüísticas y otros tipos de análisis de texto relacionados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1689003439861,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "vOhhup3JRQOj",
    "outputId": "94a31d0a-b878-431f-a9f0-c4cd357a9b44",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus consisting of 59 documents and 4 docvars.\n",
      "1789-Washington :\n",
      "\"Fellow-Citizens of the Senate and of the House of Representa...\"\n",
      "\n",
      "1793-Washington :\n",
      "\"Fellow citizens, I am again called upon by the voice of my c...\"\n",
      "\n",
      "1797-Adams :\n",
      "\"When it was first perceived, in early times, that no middle ...\"\n",
      "\n",
      "1801-Jefferson :\n",
      "\"Friends and Fellow Citizens: Called upon to undertake the du...\"\n",
      "\n",
      "1805-Jefferson :\n",
      "\"Proceeding, fellow citizens, to that qualification which the...\"\n",
      "\n",
      "1809-Madison :\n",
      "\"Unwilling to depart from examples of the most revered author...\"\n",
      "\n",
      "[ reached max_ndoc ... 53 more documents ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>'corpus'</li><li>'character'</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'corpus'\n",
       "\\item 'character'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'corpus'\n",
       "2. 'character'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"corpus\"    \"character\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(data_corpus_inaugural)\n",
    "class(data_corpus_inaugural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-pZMMPa-Fpu2"
   },
   "source": [
    "\n",
    "\n",
    "## print(corpus), docvars(corpus), summary(corpus), docnames(corpus)\n",
    "\n",
    "**docvars:** Las \"docvars\" (variables de documento) son metadatos asociados a cada documento en un corpus. Representan información adicional o atributos que pueden estar relacionados con los textos contenidos en el corpus.\n",
    "\n",
    "Las docvars son útiles para almacenar información contextual sobre los documentos, como el autor, el género, la fecha, la fuente o cualquier otro atributo relevante que se quiera asociar a los textos. Estas variables pueden ser de diferentes tipos, como cadenas de texto, fechas, números o factores categóricos.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "executionInfo": {
     "elapsed": 263,
     "status": "ok",
     "timestamp": 1689007697965,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "-pLLOZHNRzn4",
    "outputId": "b3913553-1fd0-4cf0-9873-5696ea3f0e97",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 4</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Year</th><th scope=col>President</th><th scope=col>FirstName</th><th scope=col>Party</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1789</td><td>Washington</td><td>George</td><td>none                 </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1793</td><td>Washington</td><td>George</td><td>none                 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1797</td><td>Adams     </td><td>John  </td><td>Federalist           </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1801</td><td>Jefferson </td><td>Thomas</td><td>Democratic-Republican</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1805</td><td>Jefferson </td><td>Thomas</td><td>Democratic-Republican</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1809</td><td>Madison   </td><td>James </td><td>Democratic-Republican</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 4\n",
       "\\begin{tabular}{r|llll}\n",
       "  & Year & President & FirstName & Party\\\\\n",
       "  & <int> & <chr> & <chr> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 1789 & Washington & George & none                 \\\\\n",
       "\t2 & 1793 & Washington & George & none                 \\\\\n",
       "\t3 & 1797 & Adams      & John   & Federalist           \\\\\n",
       "\t4 & 1801 & Jefferson  & Thomas & Democratic-Republican\\\\\n",
       "\t5 & 1805 & Jefferson  & Thomas & Democratic-Republican\\\\\n",
       "\t6 & 1809 & Madison    & James  & Democratic-Republican\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 4\n",
       "\n",
       "| <!--/--> | Year &lt;int&gt; | President &lt;chr&gt; | FirstName &lt;chr&gt; | Party &lt;fct&gt; |\n",
       "|---|---|---|---|---|\n",
       "| 1 | 1789 | Washington | George | none                  |\n",
       "| 2 | 1793 | Washington | George | none                  |\n",
       "| 3 | 1797 | Adams      | John   | Federalist            |\n",
       "| 4 | 1801 | Jefferson  | Thomas | Democratic-Republican |\n",
       "| 5 | 1805 | Jefferson  | Thomas | Democratic-Republican |\n",
       "| 6 | 1809 | Madison    | James  | Democratic-Republican |\n",
       "\n"
      ],
      "text/plain": [
       "  Year President  FirstName Party                \n",
       "1 1789 Washington George    none                 \n",
       "2 1793 Washington George    none                 \n",
       "3 1797 Adams      John      Federalist           \n",
       "4 1801 Jefferson  Thomas    Democratic-Republican\n",
       "5 1805 Jefferson  Thomas    Democratic-Republican\n",
       "6 1809 Madison    James     Democratic-Republican"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(docvars(data_corpus_inaugural))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aa_uud3mHQU5"
   },
   "source": [
    "**summary(corpus)**\n",
    "\n",
    "Otra forma de obtener una visión general condensada de un corpus es utilizar la función **summary()**. **summary()** es una función base de R (es decir, una función incorporada en R) y proporciona información resumida básica sobre el objeto en cuestión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 555
    },
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1689007721158,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "EfF7rEj5HRnF",
    "outputId": "02d42a54-3635-4368-acec-de592a2c2786",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Text</th><th scope=col>Types</th><th scope=col>Tokens</th><th scope=col>Sentences</th><th scope=col>Year</th><th scope=col>President</th><th scope=col>FirstName</th><th scope=col>Party</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>1</th><td>1789-Washington</td><td>625</td><td>1537</td><td>23</td><td>1789</td><td>Washington</td><td>George</td><td>none                 </td></tr>\n",
       "\t<tr><th scope=row>2</th><td>1793-Washington</td><td> 96</td><td> 147</td><td> 4</td><td>1793</td><td>Washington</td><td>George</td><td>none                 </td></tr>\n",
       "\t<tr><th scope=row>3</th><td>1797-Adams     </td><td>826</td><td>2577</td><td>37</td><td>1797</td><td>Adams     </td><td>John  </td><td>Federalist           </td></tr>\n",
       "\t<tr><th scope=row>4</th><td>1801-Jefferson </td><td>717</td><td>1923</td><td>41</td><td>1801</td><td>Jefferson </td><td>Thomas</td><td>Democratic-Republican</td></tr>\n",
       "\t<tr><th scope=row>5</th><td>1805-Jefferson </td><td>804</td><td>2380</td><td>45</td><td>1805</td><td>Jefferson </td><td>Thomas</td><td>Democratic-Republican</td></tr>\n",
       "\t<tr><th scope=row>6</th><td>1809-Madison   </td><td>535</td><td>1261</td><td>21</td><td>1809</td><td>Madison   </td><td>James </td><td>Democratic-Republican</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & Text & Types & Tokens & Sentences & Year & President & FirstName & Party\\\\\n",
       "  & <chr> & <int> & <int> & <int> & <int> & <chr> & <chr> & <fct>\\\\\n",
       "\\hline\n",
       "\t1 & 1789-Washington & 625 & 1537 & 23 & 1789 & Washington & George & none                 \\\\\n",
       "\t2 & 1793-Washington &  96 &  147 &  4 & 1793 & Washington & George & none                 \\\\\n",
       "\t3 & 1797-Adams      & 826 & 2577 & 37 & 1797 & Adams      & John   & Federalist           \\\\\n",
       "\t4 & 1801-Jefferson  & 717 & 1923 & 41 & 1801 & Jefferson  & Thomas & Democratic-Republican\\\\\n",
       "\t5 & 1805-Jefferson  & 804 & 2380 & 45 & 1805 & Jefferson  & Thomas & Democratic-Republican\\\\\n",
       "\t6 & 1809-Madison    & 535 & 1261 & 21 & 1809 & Madison    & James  & Democratic-Republican\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| <!--/--> | Text &lt;chr&gt; | Types &lt;int&gt; | Tokens &lt;int&gt; | Sentences &lt;int&gt; | Year &lt;int&gt; | President &lt;chr&gt; | FirstName &lt;chr&gt; | Party &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 1789-Washington | 625 | 1537 | 23 | 1789 | Washington | George | none                  |\n",
       "| 2 | 1793-Washington |  96 |  147 |  4 | 1793 | Washington | George | none                  |\n",
       "| 3 | 1797-Adams      | 826 | 2577 | 37 | 1797 | Adams      | John   | Federalist            |\n",
       "| 4 | 1801-Jefferson  | 717 | 1923 | 41 | 1801 | Jefferson  | Thomas | Democratic-Republican |\n",
       "| 5 | 1805-Jefferson  | 804 | 2380 | 45 | 1805 | Jefferson  | Thomas | Democratic-Republican |\n",
       "| 6 | 1809-Madison    | 535 | 1261 | 21 | 1809 | Madison    | James  | Democratic-Republican |\n",
       "\n"
      ],
      "text/plain": [
       "  Text            Types Tokens Sentences Year President  FirstName\n",
       "1 1789-Washington 625   1537   23        1789 Washington George   \n",
       "2 1793-Washington  96    147    4        1793 Washington George   \n",
       "3 1797-Adams      826   2577   37        1797 Adams      John     \n",
       "4 1801-Jefferson  717   1923   41        1801 Jefferson  Thomas   \n",
       "5 1805-Jefferson  804   2380   45        1805 Jefferson  Thomas   \n",
       "6 1809-Madison    535   1261   21        1809 Madison    James    \n",
       "  Party                \n",
       "1 none                 \n",
       "2 none                 \n",
       "3 Federalist           \n",
       "4 Democratic-Republican\n",
       "5 Democratic-Republican\n",
       "6 Democratic-Republican"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A data.frame: 6 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Text</th><th scope=col>Types</th><th scope=col>Tokens</th><th scope=col>Sentences</th><th scope=col>Year</th><th scope=col>President</th><th scope=col>FirstName</th><th scope=col>Party</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>54</th><td>2001-Bush </td><td>621</td><td>1806</td><td> 97</td><td>2001</td><td>Bush </td><td>George W.</td><td>Republican</td></tr>\n",
       "\t<tr><th scope=row>55</th><td>2005-Bush </td><td>772</td><td>2312</td><td> 99</td><td>2005</td><td>Bush </td><td>George W.</td><td>Republican</td></tr>\n",
       "\t<tr><th scope=row>56</th><td>2009-Obama</td><td>938</td><td>2689</td><td>110</td><td>2009</td><td>Obama</td><td>Barack   </td><td>Democratic</td></tr>\n",
       "\t<tr><th scope=row>57</th><td>2013-Obama</td><td>814</td><td>2317</td><td> 88</td><td>2013</td><td>Obama</td><td>Barack   </td><td>Democratic</td></tr>\n",
       "\t<tr><th scope=row>58</th><td>2017-Trump</td><td>582</td><td>1660</td><td> 88</td><td>2017</td><td>Trump</td><td>Donald J.</td><td>Republican</td></tr>\n",
       "\t<tr><th scope=row>59</th><td>2021-Biden</td><td>812</td><td>2766</td><td>216</td><td>2021</td><td>Biden</td><td>Joseph R.</td><td>Democratic</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 6 × 8\n",
       "\\begin{tabular}{r|llllllll}\n",
       "  & Text & Types & Tokens & Sentences & Year & President & FirstName & Party\\\\\n",
       "  & <chr> & <int> & <int> & <int> & <int> & <chr> & <chr> & <fct>\\\\\n",
       "\\hline\n",
       "\t54 & 2001-Bush  & 621 & 1806 &  97 & 2001 & Bush  & George W. & Republican\\\\\n",
       "\t55 & 2005-Bush  & 772 & 2312 &  99 & 2005 & Bush  & George W. & Republican\\\\\n",
       "\t56 & 2009-Obama & 938 & 2689 & 110 & 2009 & Obama & Barack    & Democratic\\\\\n",
       "\t57 & 2013-Obama & 814 & 2317 &  88 & 2013 & Obama & Barack    & Democratic\\\\\n",
       "\t58 & 2017-Trump & 582 & 1660 &  88 & 2017 & Trump & Donald J. & Republican\\\\\n",
       "\t59 & 2021-Biden & 812 & 2766 & 216 & 2021 & Biden & Joseph R. & Democratic\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 6 × 8\n",
       "\n",
       "| <!--/--> | Text &lt;chr&gt; | Types &lt;int&gt; | Tokens &lt;int&gt; | Sentences &lt;int&gt; | Year &lt;int&gt; | President &lt;chr&gt; | FirstName &lt;chr&gt; | Party &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 54 | 2001-Bush  | 621 | 1806 |  97 | 2001 | Bush  | George W. | Republican |\n",
       "| 55 | 2005-Bush  | 772 | 2312 |  99 | 2005 | Bush  | George W. | Republican |\n",
       "| 56 | 2009-Obama | 938 | 2689 | 110 | 2009 | Obama | Barack    | Democratic |\n",
       "| 57 | 2013-Obama | 814 | 2317 |  88 | 2013 | Obama | Barack    | Democratic |\n",
       "| 58 | 2017-Trump | 582 | 1660 |  88 | 2017 | Trump | Donald J. | Republican |\n",
       "| 59 | 2021-Biden | 812 | 2766 | 216 | 2021 | Biden | Joseph R. | Democratic |\n",
       "\n"
      ],
      "text/plain": [
       "   Text       Types Tokens Sentences Year President FirstName Party     \n",
       "54 2001-Bush  621   1806    97       2001 Bush      George W. Republican\n",
       "55 2005-Bush  772   2312    99       2005 Bush      George W. Republican\n",
       "56 2009-Obama 938   2689   110       2009 Obama     Barack    Democratic\n",
       "57 2013-Obama 814   2317    88       2013 Obama     Barack    Democratic\n",
       "58 2017-Trump 582   1660    88       2017 Trump     Donald J. Republican\n",
       "59 2021-Biden 812   2766   216       2021 Biden     Joseph R. Democratic"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(summary(data_corpus_inaugural))\n",
    "tail(summary(data_corpus_inaugural))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQ1zMOhaHwZp"
   },
   "source": [
    "\n",
    "\n",
    "**Types**  : Número de tokens únicos - ntype()\n",
    "\n",
    "**Tokens** : Número total de tokens – ntoken()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1689003440759,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "e-uanKD5IEXi",
    "outputId": "2057003d-3129-423e-af4a-ce024b16536f",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2001-Bush  2005-Bush 2009-Obama 2013-Obama 2017-Trump 2021-Biden \n",
      "       621        772        938        814        582        812 \n",
      " 2001-Bush  2005-Bush 2009-Obama 2013-Obama 2017-Trump 2021-Biden \n",
      "      1806       2312       2689       2317       1660       2766 \n"
     ]
    }
   ],
   "source": [
    "print(ntype(tail(data_corpus_inaugural)))\n",
    "print(ntoken(tail(data_corpus_inaugural)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CaUsSyxFI4Wh"
   },
   "source": [
    "**docnames(corpus)**\n",
    "\n",
    "Cuando se crea un corpus en quanteda, se asigna a cada documento un nombre o identificador único. Estos nombres o identificadores se almacenan en el atributo \"docnames\" del corpus. Los docnames son útiles para realizar operaciones específicas en documentos individuales dentro del corpus, como recuperar un documento en particular para su análisis o referencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1689003440761,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "NlWcgqoNV0vw",
    "outputId": "6471429d-dae7-4c4e-d826-55d724b07bfd",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"1789-Washington\" \"1793-Washington\" \"1797-Adams\"      \"1801-Jefferson\" \n",
      "[5] \"1805-Jefferson\"  \"1809-Madison\"   \n"
     ]
    }
   ],
   "source": [
    "docnames(data_corpus_inaugural) %>%\n",
    "  head() %>%\n",
    "  print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhILkpBUJXnJ"
   },
   "source": [
    "**meta(corpus):**\n",
    "\n",
    "Cada corpus también puede contener metadatos a nivel de corpus, con información sobre cualquier aspecto del mismo. Toma la forma de una lista (list)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1689003440761,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "JA6LHErRV3L2",
    "outputId": "ea81fbe0-41f8-46df-d4ad-a8fcfa01d557",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$description\n",
      "[1] \"Transcripts of all inaugural addresses delivered by United States Presidents, from Washington 1789 onward.  Data compiled by Gerhard Peters.\"\n",
      "\n",
      "$source\n",
      "[1] \"Gerhard Peters and John T. Woolley. The American Presidency Project.\"\n",
      "\n",
      "$url\n",
      "[1] \"https://www.presidency.ucsb.edu/documents/presidential-documents-archive-guidebook/inaugural-addresses\"\n",
      "\n",
      "$author\n",
      "[1] \"(various US Presidents)\"\n",
      "\n",
      "$keywords\n",
      "[1] \"political\"     \"US politics\"   \"United States\" \"presidents\"   \n",
      "[5] \"presidency\"   \n",
      "\n",
      "$title\n",
      "[1] \"US presidential inaugural address speeches\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(meta(data_corpus_inaugural))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bb-VtK2K4bw"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# **II. Tokenization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HGuVSGfjLPn5"
   },
   "source": [
    "La **tokenización** es un proceso que consiste en dividir un texto en unidades más pequeñas llamadas tokens. Un token puede ser una palabra, un número, un signo de puntuación o cualquier otra unidad significativa de texto.\n",
    "\n",
    "El objetivo de la tokenización es convertir un texto en una secuencia estructurada de tokens que luego se puede utilizar para análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Un Primer Ejemplo\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos el siguiente texto:\n",
    "\n",
    "\"Mario es un gran empresario. Creó su propia empresa a partir de un modesto emprendimiento.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my_text <- c(\n",
    "\"Mario es un gran empresario. Creó su propia empresa a partir de un modesto emprendimiento.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "my_corpus <- corpus(my_text)\n",
    "my_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks <- tokens(my_corpus)\n",
    "print(toks)\n",
    "class(toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_lower <- tokens_tolower(toks)\n",
    "print(toks_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_nopunct_stop <-tokens(toks_lower, remove_punct = TRUE) |>\n",
    "  tokens_remove(pattern = stopwords(\"es\"))\n",
    "\n",
    "toks_nopunct_stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_nopunct_stop_stem <- tokens_wordstem(toks_nopunct_stop)\n",
    "toks_nopunct_stop_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mh....\n",
    "\n",
    "La biblioteca **SnowballC** se utiliza en diversos lenguajes de programación, incluyendo R, para proporcionar implementaciones eficientes de algoritmos de stemming para diferentes idiomas. En el caso de R, se puede utilizar en conjunto con la biblioteca quanteda para realizar el stemming de palabras en textos en español u otros idiomas compatibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "install.packages(\"SnowballC\")\n",
    "library(SnowballC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_nopunct_stop_stem <- tokens_wordstem(toks_nopunct_stop, language = \"spanish\")\n",
    "toks_nopunct_stop_stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Discursos Inaugurales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "executionInfo": {
     "elapsed": 406,
     "status": "ok",
     "timestamp": 1689003441159,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "ZnFeTys4LPC1",
    "outputId": "9d030cdd-7293-40da-922d-66e2b94e48d7",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks <- tokens(data_corpus_inaugural)\n",
    "print(toks)\n",
    "class(toks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7fyLoqx7XPeJ"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Tokens, Guiones y Palabras Compuestas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk6oWeFqYh0l"
   },
   "source": [
    "**tokens(corpus), tokens(corpus, split_hyphens = TRUE)**\n",
    "\n",
    "**Texto con guiones** - \"Fellow-Citizens\", \"God-given\", \"non-believers“, \"self-reliance\", \"self-supporting\",\n",
    "\n",
    "\"well-spent\", \"well-regulated\", etc…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1689003441163,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "G5m9eUq8ZFfI",
    "outputId": "f5feff71-1317-433e-d760-6d5bc047d505",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Hypehns ----\n",
    "toks_split <- tokens(data_corpus_inaugural, split_hyphens = TRUE)\n",
    "print(toks_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1689003441165,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "QuZsYniGZdUA",
    "outputId": "69337eb6-f277-4722-f4c0-98047e622004",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "sum(ntoken(toks))\n",
    "sum(ntoken(toks_split))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9AL0QmNNZwPp"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Mayúsculas, Signos de Puntuación y \"Stop Words\"\n",
    "\n",
    "**tokens_tolower(toks)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1689003441441,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "mUWfhnrUZvG6",
    "outputId": "688cb50e-b3b2-49be-e4b5-b83b1d28d667",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_lower <- tokens_tolower(toks)\n",
    "print(toks_lower)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w9NULM6laaEn"
   },
   "source": [
    "\n",
    "\n",
    "Eliminar los signos de puntuación y las “stop words”\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 355,
     "status": "ok",
     "timestamp": 1689003441793,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "dqT-kWMCbDTf",
    "outputId": "7f7ae84c-9d00-4769-8cd1-90d4c4e98f20",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_nopunct_stop <-tokens(data_corpus_inaugural, remove_punct = TRUE) |>\n",
    "  tokens_remove(pattern = stopwords(\"en\"))\n",
    "print(toks_nopunct_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vyJF5DkTdVln"
   },
   "source": [
    "¿Qué palabras considera Quanteda como \"stop words\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1689003615873,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "SzPjS6b6dU0s",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_en <- stopwords(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 341,
     "status": "ok",
     "timestamp": 1689003634973,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "-EWsroX-aZd2",
    "outputId": "aa329abf-9046-472d-c73c-0b4292874a89",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "print(stopwords_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_sp <- stopwords(\"spanish\")\n",
    "stopwords_sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GJB9AQuTeoqv"
   },
   "source": [
    "¿Por qué eliminar las \"stop words\"?\n",
    "\n",
    "\n",
    "\n",
    "1.   Reducción del ruido: Las stopwords son palabras muy comunes en un idioma determinado, como \"el\", \"de\", \"y\", \"a\", etc. Estas palabras suelen tener poca información semántica y, en muchos casos, no aportan un valor significativo al análisis de texto. Al eliminar las stopwords, se reduce el ruido en los datos y se enfoca en las palabras más relevantes para el análisis.\n",
    "\n",
    "2.   Mejora de la eficiencia computacional: Las stopwords son palabras que aparecen con mucha frecuencia en los documentos. Al eliminarlas, se reduce la cantidad de palabras en el texto, lo que a su vez reduce la cantidad de cálculos y operaciones necesarias durante el análisis. Esto puede acelerar el procesamiento y mejorar la eficiencia computacional.\n",
    "\n",
    "\n",
    "3.   Enfocarse en el contexto y las palabras clave: Al eliminar las stopwords, se puede poner mayor énfasis en las palabras que tienen más peso semántico y contribuyen significativamente al significado y al contexto de un texto. Esto puede ayudar a identificar y analizar las palabras clave, los patrones y las relaciones más relevantes en el análisis de texto.\n",
    "\n",
    "Es importante destacar que la eliminación de stopwords no es aplicable en todos los casos y en todos los tipos de análisis de texto. En algunos casos, como el análisis de contexto o la identificación de temas generales, las stopwords pueden contener información relevante y no deben eliminarse. Por lo tanto, es esencial considerar el contexto y los objetivos del análisis antes de decidir si es apropiado eliminar o conservar las stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 515,
     "status": "ok",
     "timestamp": 1689004290212,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "bXpcsqwLf3HF",
    "outputId": "10d9fe4d-7711-401d-c894-c01c9205b54b",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks_nopunct_stop_low <- tokens(data_corpus_inaugural, remove_punct = TRUE,)  |>\n",
    "  tokens_remove(pattern = stopwords(\"en\"))  |>\n",
    "  tokens_tolower()\n",
    "\n",
    "print(toks_nopunct_stop_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2M3N4kbEgV8V"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "---\n",
    "# III. Stemming\n",
    "\n",
    "\n",
    "\n",
    "El **stemming** simplifica las palabras a su forma básica (es decir, a su raíz). Esencialmente, logra categorizar palabras muy relacionadas como idénticas en lugar de considerarlas como  diferentes. Por ejemplo, *run*, *runner*, *running* tienen la raíz *run*.\n",
    "\n",
    "\n",
    "El objetivo del stemming es reducir diferentes variantes morfológicas de una palabra a una forma común o raíz, conocida como **\"stem\"** o **\"raíz léxica\"**. El proceso de stemming ayuda a agrupar las palabras que tienen una relación semántica similar, pero que pueden tener diferentes formas debido a la conjugación, pluralización u otras modificaciones morfológicas. Al reducir las palabras a su forma base, se pueden agrupar y analizar más eficientemente, lo que facilita tareas como la búsqueda de palabras clave, la clasificación de textos o la recuperación de información.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 621
    },
    "executionInfo": {
     "elapsed": 283,
     "status": "ok",
     "timestamp": 1689004800412,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "5RFGuCn4hkio",
    "outputId": "7fc04309-fa9b-484a-d11f-55d4b611ec18",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tokens_wordstem(toks_nopunct_stop_low)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rc6P2N_oj73n"
   },
   "source": [
    "En cuanto a las limitaciones inherentes al stemming,  probablemente el problema más importante está relacionado con el **over-stemming** (situación en la que dos palabras no relacionadas se reducen a la misma raíz) y el **under-stemming** (situación en la que dos palabras relacionadas se reducen a diferentes raíces). En este sentido, trabajar con la versión *stemmed* de un corpus requiere más intervención \"humana\" para que el analista pueda evaluar correctamente el significado correcto de una palabra **stemmed**.\n",
    "(*over-stemming* y  *under-stemming* me recuerdan el trade-off entre *over-fitting* y *under-fitting* en modelos de ML).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRKB35u6qk4-"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# IV. Key Words in Context - kwic()\n",
    "\n",
    "\n",
    "**kwic()** se utiliza para crear una lista o índice alfabético de palabras de un corpus, junto con una cantidad dada de palabras antes y después de las palabras clave elegidas para contextualizar su significado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1064,
     "status": "ok",
     "timestamp": 1689007909715,
     "user": {
      "displayName": "Fernando Diaz",
      "userId": "16819680563727310863"
     },
     "user_tz": 240
    },
    "id": "fxyNU40or8ZE",
    "outputId": "bb31c5dd-d3c5-4255-ba1c-5061cf993af9",
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "toks <- tokens(data_corpus_inaugural)\n",
    "kw_inaug <- kwic(toks, pattern = c(\"liberty\", \"people\"), window = 4)\n",
    "print(tail(kw_inaug, 10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFLWya0JvZzg"
   },
   "source": [
    "Nótese que en este caso, se utiliza la versión más básica del texto tokenizado.  Al utilizar la versión básica del texto tokenizado, se pueden presentar las palabras clave junto con su contexto de manera más clara en un lenguage que hace más sencilla la interpretación humana."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPjmdKPjSG9LF9v177K8wip",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
